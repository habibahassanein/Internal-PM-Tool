from __future__ import annotations

import logging
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List
import json
from datetime import datetime

import streamlit as st

from src.handler.confluence_handler import search_confluence_optimized
from src.handler.gemini_handler import ask_gemini
from src.handler.intent_analyzer import analyze_user_intent, validate_intent
from src.handler.slack_handler import search_slack_simplified
from src.storage.cache_manager import (
    get_cached_search_results, cache_search_results,
    get_cached_intent_analysis, cache_intent_analysis,
    get_cache_manager
)
from src.agent.pm_agent import search_docs_plain, fetch_schema_details, fetch_table_data  # Integrated tools from other code

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# Page config
st.set_page_config(page_title="Incorta AI Search Assistant", page_icon="incorta.png", layout="wide")

def _validate_env() -> List[str]:
    """Return a list of missing required environment variables."""
    missing = []
    if not st.secrets.get("SLACK_USER_TOKEN"):
        missing.append("SLACK_USER_TOKEN")
    if not st.secrets.get("CONFLUENCE_URL"):
        missing.append("CONFLUENCE_URL")
    if not st.secrets.get("CONFLUENCE_EMAIL"):
        missing.append("CONFLUENCE_EMAIL")
    if not st.secrets.get("CONFLUENCE_API_TOKEN"):
        missing.append("CONFLUENCE_API_TOKEN")
    if not st.secrets.get("GEMINI_API_KEY"):
        missing.append("GEMINI_API_KEY")
    # Added from other code for new sources
    if not st.secrets.get("QDRANT_URL"):
        missing.append("QDRANT_URL")
    if not st.secrets.get("INCORTA_ENV_URL"):
        missing.append("INCORTA_ENV_URL")
    if not st.secrets.get("INCORTA_TENANT"):
        missing.append("INCORTA_TENANT")
    if not st.secrets.get("INCORTA_USERNAME"):
        missing.append("INCORTA_USERNAME")
    if not st.secrets.get("INCORTA_PASSWORD"):
        missing.append("INCORTA_PASSWORD")
    return missing

def _clean_slack_text(text: str) -> str:
    import re
    
    text = re.sub(r'<#[A-Z0-9]+\|([^>]+)>', r'#\1', text)
    text = re.sub(r'<(https?://[^|>]+)\|([^>]+)>', r'\2 (\1)', text)
    text = re.sub(r'<(https?://[^>]+)>', r'\1', text)
    text = re.sub(r'<@[A-Z0-9]+\|([^>]+)>', r'@\1', text)
    text = re.sub(r'<@([A-Z0-9]+)>', r'@unknown_user', text)
    # Handle special mentions
    text = text.replace('<!channel>', '@channel')
    text = text.replace('<!here>', '@here')
    text = text.replace('<!everyone>', '@everyone')
    
    return text

def _format_context(slack_messages: List[dict], confluence_pages: List[dict], docs_results: List[dict], zendesk_results: dict, jira_results: dict) -> str:
    parts: List[str] = []

    if slack_messages:
        parts.append("=== Slack Messages ===")
        for i, m in enumerate(slack_messages, start=1):
            timestamp = m.get('date', 'Unknown date')
            meta = f"[# {m.get('channel','?')} | @{m.get('username','?')} | {timestamp}]"
            clean_text = _clean_slack_text(m.get('text','').strip())
            line = f"{i}. {meta}\n{clean_text}\nSource: {m.get('permalink','')}\n"
            parts.append(line)

    if confluence_pages:
        parts.append("=== Confluence Pages ===")
        for i, p in enumerate(confluence_pages, start=1):
            meta = f"[{p.get('space','?')} | last modified: {p.get('last_modified','?')}]"
            excerpt = (p.get('excerpt') or '').strip()
            line = f"{i}. {p.get('title','Untitled')} {meta}\nExcerpt: {excerpt}\nSource: {p.get('url','')}\n"
            parts.append(line)

    # Added from other code
    if docs_results:
        parts.append("=== Knowledge Base (Docs) ===")
        for i, d in enumerate(docs_results, start=1):
            meta = f"[Score: {d.get('score', 0.0):.2f}]"
            text = (d.get('text') or '').strip()
            line = f"{i}. {d.get('title','Untitled')} {meta}\nExcerpt: {text[:300]}\nSource: {d.get('url','')}\n"
            parts.append(line)

    if zendesk_results and 'data' in zendesk_results:
        parts.append("=== Zendesk Tickets ===")
        data = zendesk_results['data']
        columns = data.get('columns', [])
        rows = data.get('rows', [])
        if columns and rows:
            table_str = "Columns: " + ", ".join(columns) + "\n"
            for i, row in enumerate(rows, 1):
                table_str += f"Row {i}: " + str(row) + "\n"
            parts.append(table_str)

    if jira_results and 'data' in jira_results:
        parts.append("=== Jira Issues ===")
        data = jira_results['data']
        columns = data.get('columns', [])
        rows = data.get('rows', [])
        if columns and rows:
            table_str = "Columns: " + ", ".join(columns) + "\n"
            for i, row in enumerate(rows, 1):
                table_str += f"Row {i}: " + str(row) + "\n"
            parts.append(table_str)

    return "\n".join(parts)


def _group_slack_by_channel_date(slack_results: List[dict]) -> dict:
    grouped = {}
    for m in slack_results or []:
        channel = f"#{(m.get('channel') or 'unknown').lstrip('#')}"
        date_str = m.get('date') or m.get('ts') or 'Unknown date'
        date_key = date_str.split(' ')[0] if isinstance(date_str, str) else str(date_str)
        text = (m.get('text') or '').strip().replace('\n', ' ')
        if len(text) > 200:
            text = text[:200] + '...'
        grouped.setdefault(channel, {}).setdefault(date_key, []).append(text)
    for channel in grouped:
        grouped[channel] = dict(sorted(grouped[channel].items()))
    return dict(sorted(grouped.items()))


def _group_confluence_by_space(pages: List[dict]) -> dict:
    grouped = {"Confluence": {}}
    buckets = {}
    for p in pages or []:
        parent = p.get('space') or 'General'
        child = p.get('title') or 'Untitled'
        buckets.setdefault(parent, set()).add(child)
    for parent, children in buckets.items():
        grouped["Confluence"][parent] = {
            "title": parent,
            "children": sorted(list(children))
        }
    return grouped


def _format_grouped_response(summary: str, slack_results: List[dict], conf_results: List[dict]) -> str:
    slack_grouped = _group_slack_by_channel_date(slack_results)
    conf_grouped = _group_confluence_by_space(conf_results)

    lines = []
    if summary and summary.strip():
        lines.append(f"**Summary:** {summary.strip()}")
        lines.append("")

    lines.append("**Slack Messages:**")
    lines.append("")
    if slack_grouped:
        idx = 1
        for channel, dates in slack_grouped.items():
            lines.append(f"{idx}. **Channel: {channel}**")
            for date_key, msgs in dates.items():
                preview = ", ".join(msgs[:6])
                lines.append(f"   - {date_key}: {preview}")
            lines.append("")
            idx += 1
    else:
        lines.append("(no Slack messages found)")
        lines.append("")

    lines.append("**Confluence Pages:**")
    lines.append("")
    if conf_grouped.get("Confluence"):
        lines.append("3. **Confluence**")
        for parent, info in conf_grouped["Confluence"].items():
            lines.append(f"   - Parent Wiki: {parent}")
            for child in info.get("children", [])[:10]:
                lines.append(f"     - Child: {child}")
        lines.append("")
    else:
        lines.append("(no Confluence pages found)")

    return "\n".join(lines)


def _render_sources(slack_messages: List[dict], confluence_pages: List[dict], docs_results: List[dict], zendesk_results: dict, jira_results: dict) -> None:
    with st.expander(f"Slack Messages ({len(slack_messages)} found)", expanded=False):
        if not slack_messages:
            st.info("No Slack results found.")
        else:
            for idx, m in enumerate(slack_messages, 1):
                channel = m.get('channel', 'Unknown')
                username = m.get('username', 'Unknown')
                timestamp = m.get('date', m.get('ts', ''))
                text = _clean_slack_text(m.get('text', '').strip())
                permalink = m.get('permalink', '')
                import html
                text_escaped = html.escape(text)
                st.markdown(f"""
                <div style="background-color: #f0f2f6; padding: 15px; border-radius: 8px; margin-bottom: 15px; border-left: 4px solid #4A90E2;">
                    <div style="display: flex; justify-content: space-between; margin-bottom: 8px;">
                        <span style="font-weight: 600; color: #1f1f1f;">#{channel}</span>
                        <span style="color: #666; font-size: 0.9em;">{timestamp}</span>
                    </div>
                    <div style="color: #4A90E2; font-size: 0.9em; margin-bottom: 10px;">@{username}</div>
                    <div style="color: #1f1f1f; line-height: 1.6; margin-bottom: 10px; white-space: pre-wrap;">{text_escaped}</div>
                    <a href="{permalink}" target="_blank" style="color: #4A90E2; text-decoration: none; font-size: 0.9em;">View in Slack</a>
                </div>
                """, unsafe_allow_html=True)

    with st.expander(f"Confluence Pages ({len(confluence_pages)} found)", expanded=False):
        if not confluence_pages:
            st.info("No Confluence results found.")
        else:
            for idx, p in enumerate(confluence_pages, 1):
                title = p.get('title', 'Untitled')
                space = p.get('space', 'Unknown')
                last_modified = p.get('last_modified', 'Unknown')
                excerpt = (p.get('excerpt') or '').strip()
                url = p.get('url', '')
                score = p.get('score', 0.0)
                import re
                cleaned_excerpt = re.sub(r'@@@hl@@@(.*?)@@@endhl@@@', r'\1', excerpt)
                cleaned_excerpt = re.sub(r'<[^>]+>', '', cleaned_excerpt)
                cleaned_excerpt = cleaned_excerpt.replace('&nbsp;', ' ').replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
                if len(cleaned_excerpt) > 300:
                    cleaned_excerpt = cleaned_excerpt[:300] + '...'
                st.markdown(f"""
                <div style="background-color: #f0f2f6; padding: 15px; border-radius: 8px; margin-bottom: 15px; border-left: 4px solid #6B46C1;">
                    <div style="font-weight: 600; color: #1f1f1f; font-size: 1.1em; margin-bottom: 8px;">{title}</div>
                    <div style="display: flex; gap: 15px; margin-bottom: 10px; font-size: 0.9em;">
                        <span style="color: #6B46C1; font-weight: 500;">{space}</span>
                        <span style="color: #666;">{last_modified}</span>
                        <span style="color: #888;">Score: {score:.2f}</span>
                    </div>
                    <div style="color: #444; line-height: 1.6; margin-bottom: 10px; font-style: italic;">{cleaned_excerpt}</div>
                    <a href="{url}" target="_blank" style="color: #6B46C1; text-decoration: none; font-size: 0.9em;">Open Page</a>
                </div>
                """, unsafe_allow_html=True)

    # Added render for new sources
    with st.expander(f"Knowledge Base Docs ({len(docs_results)} found)", expanded=False):
        if not docs_results:
            st.info("No docs results found.")
        else:
            for idx, d in enumerate(docs_results, 1):
                title = d.get('title', 'Untitled')
                url = d.get('url', '')
                text = (d.get('text') or '').strip()
                score = d.get('score', 0.0)
                if len(text) > 300:
                    text = text[:300] + '...'
                st.markdown(f"""
                <div style="background-color: #f0f2f6; padding: 15px; border-radius: 8px; margin-bottom: 15px; border-left: 4px solid #28a745;">
                    <div style="font-weight: 600; color: #1f1f1f; font-size: 1.1em; margin-bottom: 8px;">{title}</div>
                    <div style="color: #666; font-size: 0.9em; margin-bottom: 10px;">Score: {score:.2f}</div>
                    <div style="color: #444; line-height: 1.6; margin-bottom: 10px;">{text}</div>
                    <a href="{url}" target="_blank" style="color: #28a745; text-decoration: none; font-size: 0.9em;">Open Document</a>
                </div>
                """, unsafe_allow_html=True)

    with st.expander(f"Zendesk Tickets (Results found)", expanded=False):
        if not zendesk_results or 'data' not in zendesk_results:
            st.info("No Zendesk results found.")
        else:
            data = zendesk_results['data']
            columns = data.get('columns', [])
            rows = data.get('rows', [])
            if columns and rows:
                st.table({"Columns": columns, "Rows": rows})

    with st.expander(f"Jira Issues (Results found)", expanded=False):
        if not jira_results or 'data' not in jira_results:
            st.info("No Jira results found.")
        else:
            data = jira_results['data']
            columns = data.get('columns', [])
            rows = data.get('rows', [])
            if columns and rows:
                st.table({"Columns": columns, "Rows": rows})

def generate_sql_for_schema(schema_name: str, query: str) -> str:
    schema_details = fetch_schema_details(schema_name)
    if 'error' in schema_details:
        return ""
    
    schema_json = json.dumps(schema_details, indent=2)
    
    sql_prompt = f"""
    You are a SQL query generator for Incorta schemas.
    Schema details: {schema_json}
    
    User query: {query}
    
    Generate a valid Spark SQL query to answer the query.
    Use the schema tables and columns appropriately.
    Return ONLY the SQL query, no explanations.
    """
    
    sql_response = ask_gemini(sql_prompt, "")
    return sql_response.strip()

def main() -> None:
    st.title("Incorta AI Search Assistant Tool")
    st.caption("Searches Slack, Confluence, Docs, Zendesk, Jira, then asks Gemini to synthesize an answer with sources.")

    missing = _validate_env()
    if missing:
        st.warning("Missing environment variables: " + ", ".join(missing) + ". Set them to enable full functionality.")

    if "search_history" not in st.session_state:
        st.session_state["search_history"] = []

    with st.sidebar:
        st.markdown("<h1 style=\"margin-top:0; margin-bottom:0.25rem; font-size:1.6rem;\">Search Options</h1>", unsafe_allow_html=True)
        
        st.divider()
        
        st.subheader("Filters")
        channel_hint = st.text_input("Slack channel", value=st.session_state.get("channel_hint", ""), 
                                     key="channel_hint", placeholder="e.g., general, engineering")
        space_hint = st.text_input("Confluence space", value=st.session_state.get("space_hint", ""), 
                                   key="space_hint", placeholder="e.g., PROJ, DOCS")

        st.divider()
        auto_refresh = True
        
    if "chat_messages" not in st.session_state:
        st.session_state["chat_messages"] = [
            {"role": "assistant", "content": "Hi! Ask me anything. I'll search Slack, Confluence, Docs, Zendesk, Jira, then summarize with sources."}
        ]
    
    if "context" not in st.session_state:
        st.session_state["context"] = None
    if "slack_results" not in st.session_state:
        st.session_state["slack_results"] = []
    if "conf_results" not in st.session_state:
        st.session_state["conf_results"] = []
    if "filters" not in st.session_state:
        st.session_state["filters"] = {}

    for msg in st.session_state["chat_messages"]:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    user_input = st.chat_input("Type your question")

    if user_input:
        st.session_state["chat_messages"].append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.write(user_input)

        with st.chat_message("assistant"):
            current_filters = {
                "channel_hint": (channel_hint or "").strip(),
                "space_hint": (space_hint or "").strip(),
            }
            stored_filters = st.session_state.get("filters", {})
            filters_changed = current_filters != stored_filters

            intent_type = ""
            if "intent_data" in st.session_state:
                intent_type = st.session_state["intent_data"].get("intent", "")
            
            reuse_context = (not auto_refresh) and (not filters_changed) and bool(st.session_state.get("context")) and (intent_type != "latest_message")

            if reuse_context:
                context = st.session_state.get("context") or ""
                slack_results = st.session_state.get("slack_results") or []
                conf_results = st.session_state.get("conf_results") or []
                docs_results = st.session_state.get("docs_results") or []
                zendesk_results = st.session_state.get("zendesk_results") or {}
                jira_results = st.session_state.get("jira_results") or {}
            else:
                with st.spinner("Analyzing query and retrieving sources..."):
                    cache_filters = {
                        "channel_hint": (channel_hint or "").strip(),
                        "space_hint": (space_hint or "").strip(),
                    }
                    
                    intent_data = get_cached_intent_analysis(user_input, cache_filters)
                    
                    if not intent_data:
                        intent_data = analyze_user_intent(user_input)
                        intent_data = validate_intent(intent_data)
                        cache_intent_analysis(user_input, cache_filters, intent_data)
                    
                    if channel_hint and channel_hint.strip():
                        intent_data["slack_params"]["channels"] = channel_hint.strip()
                    if space_hint and space_hint.strip():
                        intent_data["confluence_params"]["spaces"] = space_hint.strip()

                    logger.info(f"Intent analysis result: {intent_data}")
                    
                    slack_results: List[dict] = []
                    conf_results: List[dict] = []
                    docs_results: List[dict] = []
                    zendesk_results: dict = {}
                    jira_results: dict = {}

                    data_sources = intent_data.get("data_sources", ["slack", "confluence"])

                    with ThreadPoolExecutor(max_workers=5) as pool:
                        futures = {}

                        if "slack" in data_sources:
                            futures["slack"] = pool.submit(
                                search_slack_simplified,
                                user_input,
                                intent_data,
                                15
                            )
                        
                        if "confluence" in data_sources:
                            futures["confluence"] = pool.submit(
                                search_confluence_optimized,
                                intent_data,
                                user_input
                            )
                        
                        # Knowledge base (Docs) search: enable for doc-style queries even if not explicitly requested
                        def _should_search_docs(query: str) -> bool:
                            q = (query or "").lower()
                            doc_terms = [
                                "how to", "install", "installation", "setup", "configure",
                                "documentation", "doc", "guide", "on prem", "on-prem"
                            ]
                            return any(t in q for t in doc_terms)

                        if any(s in data_sources for s in ["docs", "knowledge_base"]) or _should_search_docs(user_input):
                            futures["docs"] = pool.submit(search_docs_plain, user_input, 5)
                        
                        if "zendesk" in data_sources:
                            zendesk_schema = fetch_schema_details("ZendeskTickets")
                            zendesk_sql = generate_sql_for_schema("ZendeskTickets", user_input)
                            if zendesk_sql:
                                futures["zendesk"] = pool.submit(
                                    fetch_table_data,
                                    zendesk_sql
                                )
                        
                        if "jira" in data_sources:
                            jira_schema = fetch_schema_details("Jira_F")
                            jira_sql = generate_sql_for_schema("Jira_F", user_input)
                            if jira_sql:
                                futures["jira"] = pool.submit(
                                    fetch_table_data,
                                    jira_sql
                                )
                        
                        for source, future in futures.items():
                            try:
                                if source == "slack":
                                    slack_results = future.result(timeout=75)
                                elif source == "confluence":
                                    conf_results = future.result(timeout=60)
                                elif source == "docs":
                                    docs_results = future.result(timeout=30)
                                elif source == "zendesk":
                                    zendesk_results = future.result(timeout=60)
                                elif source == "jira":
                                    jira_results = future.result(timeout=60)
                            except Exception as e:
                                logger.error(f"{source.title()} search failed: {e}")
                                if "timeout" in str(e).lower():
                                    st.warning(f"⏱️ {source.title()} search timed out.")
                                else:
                                    st.warning(f"⚠️ {source.title()} search encountered an issue: {str(e)}")

                    if not slack_results and not conf_results and not docs_results and not zendesk_results and not jira_results:
                        nores = "No results found in any source. Try adjusting your query or filters."
                        st.write(nores)
                        st.session_state["chat_messages"].append({"role": "assistant", "content": nores})
                        return
                    
                    context = _format_context(slack_results, conf_results, docs_results, zendesk_results, jira_results)
                    st.session_state["context"] = context
                    st.session_state["slack_results"] = slack_results
                    st.session_state["conf_results"] = conf_results
                    st.session_state["docs_results"] = docs_results
                    st.session_state["zendesk_results"] = zendesk_results
                    st.session_state["jira_results"] = jira_results
                    st.session_state["filters"] = current_filters
                    st.session_state["intent_data"] = intent_data

            preface = ("Previous conversation context (use for continuity):\n" + "\n".join([f"{prefix} {m['content']}" for m in st.session_state["chat_messages"][-6:] if (prefix := "User:" if m["role"] == "user" else "Assistant:")]) + "\n\n") if st.session_state["chat_messages"][-6:] else ""

            with st.spinner("Thinking..."):
                # Generate concise summary only
                try:
                    context_for_summary = context or _format_context(slack_results, conf_results, docs_results, zendesk_results, jira_results)
                    summary_prompt = (
                        "Write a concise 2-4 sentence summary answering the user's question directly. "
                        "Include what the feature/release is, who is responsible (if available), current status, and key updates.\n\n"
                        f"User question: {user_input}\n\nContext:\n{context_for_summary}"
                    )
                    summary_text = ask_gemini(summary_prompt, "") or ""
                except Exception:
                    summary_text = ""

            grouped_output = _format_grouped_response(
                summary_text,
                slack_results,
                conf_results,
            )

            st.markdown(grouped_output)

            # Agent Trace: log to terminal instead of UI
            try:
                strategies = [r.get('strategy') for r in (slack_results or []) if r.get('strategy')]
                strat_counts = {}
                for s in strategies:
                    strat_counts[s] = strat_counts.get(s, 0) + 1
                channels = sorted({r.get('channel') for r in (slack_results or []) if r.get('channel')})
                conf_top = ", ".join([c.get('title','') for c in (conf_results or [])[:5]])
                docs_top = ", ".join([d.get('title','') for d in (docs_results or [])[:5]])
                if strat_counts:
                    logger.info("Agent Trace: Slack strategies used: " + ", ".join([f"{k} x{v}" for k,v in strat_counts.items()]))
                if channels:
                    logger.info("Agent Trace: Slack channels searched: " + ", ".join([f"#{c}" for c in channels]))
                logger.info(f"Agent Trace: Confluence results: {len(conf_results or [])}; Top: {conf_top}")
                logger.info(f"Agent Trace: Docs results: {len(docs_results or [])}; Top: {docs_top}")
            except Exception:
                pass

            if slack_results or conf_results or docs_results or zendesk_results or jira_results:
                _render_sources(slack_results, conf_results, docs_results, zendesk_results, jira_results)
            
            st.session_state["chat_messages"].append({"role": "assistant", "content": grouped_output})

            new_entry = {
                "question": user_input.strip(),
                "channel_hint": (channel_hint or "").strip() or None,
                "space_hint": (space_hint or "").strip() or None,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"),
            }
            if not st.session_state["search_history"] or st.session_state["search_history"][0].get("question") != new_entry["question"]:
                st.session_state["search_history"].insert(0, new_entry)
                if len(st.session_state["search_history"]) > 50:
                    st.session_state["search_history"] = st.session_state["search_history"][:50]

if __name__ == "__main__":
    main()